{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import numpy\n",
    "import heapq\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_All = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "training_files = glob.glob('data/training/*')\n",
    "training_df = pd.DataFrame()\n",
    "for index, filename in enumerate(training_files):\n",
    "    with open(filename) as f:\n",
    "        data = (line.strip() for line in f)\n",
    "        data_json = \"[{0}]\".format(','.join(data))\n",
    "    training_df = pd.concat([training_df, pd.read_json(data_json)], ignore_index=True)\n",
    "    # for memory reserve\n",
    "    if Train_All == False and index == 10: \n",
    "        break\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>browser</th>\n",
       "      <th>browser_version</th>\n",
       "      <th>category_id</th>\n",
       "      <th>city</th>\n",
       "      <th>cookie_pta</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_marketing</th>\n",
       "      <th>hour</th>\n",
       "      <th>os</th>\n",
       "      <th>os_version</th>\n",
       "      <th>resolution</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>milk52313</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>20a466bc8756f1f28988bf2e65fd9efeff055d6bb35ab3...</td>\n",
       "      <td>美味食記</td>\n",
       "      <td></td>\n",
       "      <td>227f747d3020961ca7545dc91166ea893a452f6c965f67...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150519</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>Windows XP</td>\n",
       "      <td></td>\n",
       "      <td>1024x768</td>\n",
       "      <td>2015-05-19 08:37:53</td>\n",
       "      <td>http://milk52313.pixnet.net/blog/post/423828488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qpjj</td>\n",
       "      <td>Other</td>\n",
       "      <td></td>\n",
       "      <td>美味食記</td>\n",
       "      <td></td>\n",
       "      <td>71f285727d205b8a7c54a765f3f6cd545dd3288786db7e...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150327</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>Windows 7</td>\n",
       "      <td></td>\n",
       "      <td>1024x819</td>\n",
       "      <td>2015-03-27 05:56:27</td>\n",
       "      <td>http://qpjj.pixnet.net/blog/post/5103901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dreampudding</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>781faba9107b3b9909066c4e40793fa308ea8a5a5dc6e8...</td>\n",
       "      <td>美味食記</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>5b58b3f61bc8c0a47eb2126c3ac35cd85d4482e1abd1a7...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150811</td>\n",
       "      <td>hTC</td>\n",
       "      <td>87fde507ac9c015aa48a00cbf8d5678817ed4571c33a16...</td>\n",
       "      <td>20</td>\n",
       "      <td>Android</td>\n",
       "      <td>f374e854df9a0650ff3fb3923e02806cf7f595a53c73f5...</td>\n",
       "      <td>360x640</td>\n",
       "      <td>2015-08-11 12:43:11</td>\n",
       "      <td>http://dreampudding.pixnet.net/blog/post/41912680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dreampudding</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>781faba9107b3b9909066c4e40793fa308ea8a5a5dc6e8...</td>\n",
       "      <td>美味食記</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>5b58b3f61bc8c0a47eb2126c3ac35cd85d4482e1abd1a7...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150811</td>\n",
       "      <td>hTC</td>\n",
       "      <td>87fde507ac9c015aa48a00cbf8d5678817ed4571c33a16...</td>\n",
       "      <td>20</td>\n",
       "      <td>Android</td>\n",
       "      <td>f374e854df9a0650ff3fb3923e02806cf7f595a53c73f5...</td>\n",
       "      <td>360x640</td>\n",
       "      <td>2015-08-11 12:44:57</td>\n",
       "      <td>http://dreampudding.pixnet.net/blog/post/41912680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cline1413</td>\n",
       "      <td>Chrome Mobile</td>\n",
       "      <td>20a466bc8756f1f28988bf2e65fd9efeff055d6bb35ab3...</td>\n",
       "      <td>親子育兒</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>82452818954eefeb18d6fbeb5d8bb4e4205b273172ba3d...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150418</td>\n",
       "      <td>hTC</td>\n",
       "      <td>344e4fe44f21d600cb04ee706d0ba43131c888d8a08f79...</td>\n",
       "      <td>13</td>\n",
       "      <td>Android</td>\n",
       "      <td>fda195ecd026e4e46842394ef8ee552261bdd0fd03b6e7...</td>\n",
       "      <td>360x640</td>\n",
       "      <td>2015-04-18 05:10:59</td>\n",
       "      <td>http://cline1413.pixnet.net/blog/post/390634931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author_id        browser  \\\n",
       "0     milk52313         Chrome   \n",
       "1          qpjj          Other   \n",
       "2  dreampudding  Chrome Mobile   \n",
       "3  dreampudding  Chrome Mobile   \n",
       "4     cline1413  Chrome Mobile   \n",
       "\n",
       "                                     browser_version category_id    city  \\\n",
       "0  20a466bc8756f1f28988bf2e65fd9efeff055d6bb35ab3...        美味食記           \n",
       "1                                                           美味食記           \n",
       "2  781faba9107b3b9909066c4e40793fa308ea8a5a5dc6e8...        美味食記  Taipei   \n",
       "3  781faba9107b3b9909066c4e40793fa308ea8a5a5dc6e8...        美味食記  Taipei   \n",
       "4  20a466bc8756f1f28988bf2e65fd9efeff055d6bb35ab3...        親子育兒  Taipei   \n",
       "\n",
       "                                          cookie_pta country      date  \\\n",
       "0  227f747d3020961ca7545dc91166ea893a452f6c965f67...      TW  20150519   \n",
       "1  71f285727d205b8a7c54a765f3f6cd545dd3288786db7e...      TW  20150327   \n",
       "2  5b58b3f61bc8c0a47eb2126c3ac35cd85d4482e1abd1a7...      TW  20150811   \n",
       "3  5b58b3f61bc8c0a47eb2126c3ac35cd85d4482e1abd1a7...      TW  20150811   \n",
       "4  82452818954eefeb18d6fbeb5d8bb4e4205b273172ba3d...      TW  20150418   \n",
       "\n",
       "  device_brand                                   device_marketing  hour  \\\n",
       "0                                                                    16   \n",
       "1                                                                    13   \n",
       "2          hTC  87fde507ac9c015aa48a00cbf8d5678817ed4571c33a16...    20   \n",
       "3          hTC  87fde507ac9c015aa48a00cbf8d5678817ed4571c33a16...    20   \n",
       "4          hTC  344e4fe44f21d600cb04ee706d0ba43131c888d8a08f79...    13   \n",
       "\n",
       "           os                                         os_version resolution  \\\n",
       "0  Windows XP                                                      1024x768   \n",
       "1   Windows 7                                                      1024x819   \n",
       "2     Android  f374e854df9a0650ff3fb3923e02806cf7f595a53c73f5...    360x640   \n",
       "3     Android  f374e854df9a0650ff3fb3923e02806cf7f595a53c73f5...    360x640   \n",
       "4     Android  fda195ecd026e4e46842394ef8ee552261bdd0fd03b6e7...    360x640   \n",
       "\n",
       "            timestamp                                                url  \n",
       "0 2015-05-19 08:37:53    http://milk52313.pixnet.net/blog/post/423828488  \n",
       "1 2015-03-27 05:56:27           http://qpjj.pixnet.net/blog/post/5103901  \n",
       "2 2015-08-11 12:43:11  http://dreampudding.pixnet.net/blog/post/41912680  \n",
       "3 2015-08-11 12:44:57  http://dreampudding.pixnet.net/blog/post/41912680  \n",
       "4 2015-04-18 05:10:59    http://cline1413.pixnet.net/blog/post/390634931  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode str col\n",
    "trainEnc_df = training_df.copy()\n",
    "encode_dict = {}\n",
    "\n",
    "M_dict = [ {} for _ in range(12)]\n",
    "def encode_series(series):\n",
    "    x = series.astype('category')\n",
    "    encode_series = x.cat.codes\n",
    "    dict_df = pd.concat([x.cat.codes, series], axis=1)\n",
    "    series_dict = dict_df.drop_duplicates().sort_values(0).set_index(0).to_dict()\n",
    "    \n",
    "    return encode_series, series_dict\n",
    "trainEnc_df.browser           ,M_dict[0] = encode_series(trainEnc_df.browser); \n",
    "trainEnc_df.browser_version   ,M_dict[1] = encode_series(trainEnc_df.browser_version)\n",
    "trainEnc_df.category_id       ,M_dict[2] = encode_series(trainEnc_df.category_id)\n",
    "trainEnc_df.city              ,M_dict[3] = encode_series(trainEnc_df.city)\n",
    "trainEnc_df.country           ,M_dict[4] = encode_series(trainEnc_df.country)\n",
    "trainEnc_df.device_brand      ,M_dict[5] = encode_series(trainEnc_df.device_brand)\n",
    "trainEnc_df.device_marketing  ,M_dict[6] = encode_series(trainEnc_df.device_marketing)\n",
    "trainEnc_df.os                ,M_dict[7] = encode_series(trainEnc_df.os)\n",
    "trainEnc_df.os_version        ,M_dict[8] = encode_series(trainEnc_df.os_version)\n",
    "trainEnc_df.resolution        ,M_dict[9] = encode_series(trainEnc_df.resolution)\n",
    "trainEnc_df.cookie_pta        ,M_dict[10]= encode_series(trainEnc_df.cookie_pta)\n",
    "trainEnc_df.author_id         ,M_dict[11]= encode_series(trainEnc_df.author_id)\n",
    "\n",
    "for i in range(12):\n",
    "    encode_dict.update(M_dict[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>browser</th>\n",
       "      <th>browser_version</th>\n",
       "      <th>category_id</th>\n",
       "      <th>city</th>\n",
       "      <th>cookie_pta</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_marketing</th>\n",
       "      <th>hour</th>\n",
       "      <th>os</th>\n",
       "      <th>os_version</th>\n",
       "      <th>resolution</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>911291</th>\n",
       "      <td>imlabor</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>4f5e86ee9a73052d24b5adf4811f2e17cdd12eaa57a39c...</td>\n",
       "      <td>職場甘苦</td>\n",
       "      <td></td>\n",
       "      <td>d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150727</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>Windows</td>\n",
       "      <td></td>\n",
       "      <td>1280x720</td>\n",
       "      <td>2015-07-27 02:16:54</td>\n",
       "      <td>http://imlabor.pixnet.net/blog/post/40548034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055685</th>\n",
       "      <td>imlabor</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>4f5e86ee9a73052d24b5adf4811f2e17cdd12eaa57a39c...</td>\n",
       "      <td>職場甘苦</td>\n",
       "      <td></td>\n",
       "      <td>d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150727</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>Windows</td>\n",
       "      <td></td>\n",
       "      <td>1280x720</td>\n",
       "      <td>2015-07-27 02:17:22</td>\n",
       "      <td>http://imlabor.pixnet.net/blog/post/35262433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148030</th>\n",
       "      <td>ifans</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>f8cd71688b6403c74a463d0d7883a5e8fdb842f0c61482...</td>\n",
       "      <td>數位生活</td>\n",
       "      <td></td>\n",
       "      <td>d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150415</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>Windows</td>\n",
       "      <td></td>\n",
       "      <td>1280x720</td>\n",
       "      <td>2015-04-15 00:53:02</td>\n",
       "      <td>http://ifans.pixnet.net/blog/post/196598139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442670</th>\n",
       "      <td>kellyla1028</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>f8cd71688b6403c74a463d0d7883a5e8fdb842f0c61482...</td>\n",
       "      <td>裝潢設計</td>\n",
       "      <td>Taipei</td>\n",
       "      <td>d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150323</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>Windows</td>\n",
       "      <td></td>\n",
       "      <td>1280x720</td>\n",
       "      <td>2015-03-23 01:20:46</td>\n",
       "      <td>http://kellyla1028.pixnet.net/blog/post/44586085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215094</th>\n",
       "      <td>a0912414333</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>1d18d077ea3991866820b908da17138e2be22951bb8a3c...</td>\n",
       "      <td>醫療保健</td>\n",
       "      <td></td>\n",
       "      <td>d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150623</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13</td>\n",
       "      <td>Windows</td>\n",
       "      <td></td>\n",
       "      <td>1280x720</td>\n",
       "      <td>2015-06-23 05:12:07</td>\n",
       "      <td>http://a0912414333.pixnet.net/blog/post/188212776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author_id browser  \\\n",
       "911291       imlabor  Chrome   \n",
       "1055685      imlabor  Chrome   \n",
       "1148030        ifans  Chrome   \n",
       "1442670  kellyla1028  Chrome   \n",
       "4215094  a0912414333  Chrome   \n",
       "\n",
       "                                           browser_version category_id  \\\n",
       "911291   4f5e86ee9a73052d24b5adf4811f2e17cdd12eaa57a39c...        職場甘苦   \n",
       "1055685  4f5e86ee9a73052d24b5adf4811f2e17cdd12eaa57a39c...        職場甘苦   \n",
       "1148030  f8cd71688b6403c74a463d0d7883a5e8fdb842f0c61482...        數位生活   \n",
       "1442670  f8cd71688b6403c74a463d0d7883a5e8fdb842f0c61482...        裝潢設計   \n",
       "4215094  1d18d077ea3991866820b908da17138e2be22951bb8a3c...        醫療保健   \n",
       "\n",
       "           city                                         cookie_pta country  \\\n",
       "911291           d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...      TW   \n",
       "1055685          d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...      TW   \n",
       "1148030          d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...      TW   \n",
       "1442670  Taipei  d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...      TW   \n",
       "4215094          d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...      TW   \n",
       "\n",
       "             date device_brand device_marketing  hour       os os_version  \\\n",
       "911291   20150727                                  10  Windows              \n",
       "1055685  20150727                                  10  Windows              \n",
       "1148030  20150415                                   8  Windows              \n",
       "1442670  20150323                                   9  Windows              \n",
       "4215094  20150623                                  13  Windows              \n",
       "\n",
       "        resolution           timestamp  \\\n",
       "911291    1280x720 2015-07-27 02:16:54   \n",
       "1055685   1280x720 2015-07-27 02:17:22   \n",
       "1148030   1280x720 2015-04-15 00:53:02   \n",
       "1442670   1280x720 2015-03-23 01:20:46   \n",
       "4215094   1280x720 2015-06-23 05:12:07   \n",
       "\n",
       "                                                       url  \n",
       "911291        http://imlabor.pixnet.net/blog/post/40548034  \n",
       "1055685       http://imlabor.pixnet.net/blog/post/35262433  \n",
       "1148030        http://ifans.pixnet.net/blog/post/196598139  \n",
       "1442670   http://kellyla1028.pixnet.net/blog/post/44586085  \n",
       "4215094  http://a0912414333.pixnet.net/blog/post/188212776  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.loc[training_df.cookie_pta == 'd5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f71c66c1334']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 10    # how many neurons in the hidden layer\n",
    "activation = 'sigmoid'  # activation function for hidden layer\n",
    "l2 = 0.001           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 0.01  # how big our steps are in gradient descent\n",
    "epochs = 50          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(series, num):\n",
    "    encode = list()\n",
    "    for s in series:\n",
    "        letter = [0 for _ in range(num)]\n",
    "        letter[s] = 1\n",
    "        encode.append(letter)\n",
    "    return encode\n",
    "trainEnc1_df.author_id = one_hot_encode(trainEnc_df.author_id, len(encode_dict['author_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers, regularizers\n",
    "import keras\n",
    "\n",
    "\n",
    "train_X = trainEnc_df.copy().drop(['author_id', 'date', 'timestamp', 'url'], axis=1)\n",
    "train_y = trainEnc_df.author_id\n",
    "    \n",
    "\n",
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add ( layers.Dense ( input_dim = 12,\n",
    "                       units = hidden_units, \n",
    "                       activation = activation ) )\n",
    "\n",
    "# add the output layer\n",
    "model.add ( layers.Dense ( input_dim = hidden_units,\n",
    "                       units = 1,\n",
    "                       activation = 'sigmoid' ) )\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile ( loss = 'sparse_categorical_crossentropy',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer = optimizers.Adam ( lr = learning_rate ),\n",
    "              metrics = [ 'accuracy' ] \n",
    "                )\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit ( train_X, train_y, epochs = 3, batch_size = batch_size )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4887580/4887580 [==============================] - 78s 16us/step\n",
      "Training accuracy: 2965982.6844796403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate ( train_X, train_y, batch_size = 32 )\n",
    "# test_acc = model.evaluate ( test_X, test_y, batch_size = 32 )[1]\n",
    "print ( 'Training accuracy: %s' % train_acc )\n",
    "#print ( 'Testing accuracy: %s' % test_acc )\n",
    "\n",
    "losses = history.history['loss']\n",
    "#plt.plot ( range ( len ( losses ) ), losses, 'r' )\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>browser</th>\n",
       "      <th>browser_version</th>\n",
       "      <th>category_id</th>\n",
       "      <th>city</th>\n",
       "      <th>cookie_pta</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_marketing</th>\n",
       "      <th>hour</th>\n",
       "      <th>os</th>\n",
       "      <th>os_version</th>\n",
       "      <th>resolution</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1055685</th>\n",
       "      <td>imlabor</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>4f5e86ee9a73052d24b5adf4811f2e17cdd12eaa57a39c...</td>\n",
       "      <td>職場甘苦</td>\n",
       "      <td></td>\n",
       "      <td>d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...</td>\n",
       "      <td>TW</td>\n",
       "      <td>20150727</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>Windows</td>\n",
       "      <td></td>\n",
       "      <td>1280x720</td>\n",
       "      <td>2015-07-27 02:17:22</td>\n",
       "      <td>http://imlabor.pixnet.net/blog/post/35262433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author_id browser                                    browser_version  \\\n",
       "1055685   imlabor  Chrome  4f5e86ee9a73052d24b5adf4811f2e17cdd12eaa57a39c...   \n",
       "\n",
       "        category_id city                                         cookie_pta  \\\n",
       "1055685        職場甘苦       d5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f...   \n",
       "\n",
       "        country      date device_brand device_marketing  hour       os  \\\n",
       "1055685      TW  20150727                                  10  Windows   \n",
       "\n",
       "        os_version resolution           timestamp  \\\n",
       "1055685              1280x720 2015-07-27 02:17:22   \n",
       "\n",
       "                                                  url  \n",
       "1055685  http://imlabor.pixnet.net/blog/post/35262433  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_latest_cookie_info(df, in_cookie):\n",
    "    df_group = df.loc[df.cookie_pta == in_cookie]\n",
    "    return df_group.loc[df_group.timestamp == df_group.timestamp.max()]\n",
    "get_latest_cookie_info(training_df, 'd5d9ba4a82443aab3a4a0b59ef1aeacd14ea934bfe7d3f71c66c1334')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 10    # how many neurons in the hidden layer\n",
    "activation = 'sigmoid'  # activation function for hidden layer\n",
    "l2 = 0.001           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 0.01  # how big our steps are in gradient descent\n",
    "epochs = 50          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10621620/10621620 [==============================] - 305s 29us/step - loss: 1.2461e-04\n",
      "Epoch 2/5\n",
      "10621620/10621620 [==============================] - 304s 29us/step - loss: 1.2437e-04\n",
      "Epoch 3/5\n",
      "10621620/10621620 [==============================] - 304s 29us/step - loss: 1.2437e-04\n",
      "Epoch 4/5\n",
      "10621620/10621620 [==============================] - 304s 29us/step - loss: 1.2437e-04\n",
      "Epoch 5/5\n",
      "10621620/10621620 [==============================] - 305s 29us/step - loss: 1.2437e-04\n"
     ]
    }
   ],
   "source": [
    "train_X = trainEnc_df.cookie_pta\n",
    "train_y = trainEnc_df.author_id\n",
    "    \n",
    "from keras import models, layers, optimizers, regularizers\n",
    "import keras\n",
    "\n",
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add ( layers.Dense ( input_dim = 1,\n",
    "                       units = hidden_units, \n",
    "                       activation = activation ) )\n",
    "\n",
    "# add the output layer\n",
    "model.add ( layers.Dense ( input_dim = hidden_units,\n",
    "                       units = 1,\n",
    "                       activation = 'sigmoid' ) )\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile ( loss = 'hinge',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer = optimizers.Adam ( lr = learning_rate ),\n",
    "              #metrics = [ 'accuracy' ] \n",
    "                )\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit ( train_X, train_y, epochs = 5, batch_size = batch_size )\n",
    "\n",
    "# # evaluate accuracy\n",
    "# train_acc = model.evaluate ( train_X, train_y, batch_size = 32 )[1]\n",
    "# test_acc = model.evaluate ( test_X, test_y, batch_size = 32 )[1]\n",
    "# print ( 'Training accuracy: %s' % train_acc )\n",
    "# print ( 'Testing accuracy: %s' % test_acc )\n",
    "\n",
    "# losses = history.history['loss']\n",
    "# plt.plot ( range ( len ( losses ) ), losses, 'r' )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10621620/10621620 [==============================] - 109s 10us/step\n",
      "Training accuracy: 0.00012436897573063244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate ( train_X, train_y, batch_size = 32 )\n",
    "# test_acc = model.evaluate ( test_X, test_y, batch_size = 32 )[1]\n",
    "print ( 'Training accuracy: %s' % train_acc )\n",
    "#print ( 'Testing accuracy: %s' % test_acc )\n",
    "\n",
    "losses = history.history['loss']\n",
    "#plt.plot ( range ( len ( losses ) ), losses, 'r' )\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 10    # how many neurons in the hidden layer\n",
    "activation = 'sigmoid'  # activation function for hidden layer\n",
    "l2 = 0.001           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 0.01  # how big our steps are in gradient descent\n",
    "epochs = 2          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10621620/10621620 [==============================] - 338s 32us/step - loss: 0.0013\n",
      "Epoch 2/2\n",
      "10621620/10621620 [==============================] - 325s 31us/step - loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "train_X = trainEnc_df.cookie_pta\n",
    "train_y = trainEnc_df.category_id\n",
    "    \n",
    "from keras import models, layers, optimizers, regularizers\n",
    "import keras\n",
    "\n",
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# add the hidden layer\n",
    "model.add ( layers.Dense ( input_dim = 1,\n",
    "                       units = hidden_units, \n",
    "                       activation = activation ) )\n",
    "\n",
    "# add the output layer\n",
    "model.add ( layers.Dense ( input_dim = hidden_units,\n",
    "                       units = 1,\n",
    "                       activation = 'sigmoid' ) )\n",
    "\n",
    "# define our loss function and optimizer\n",
    "model.compile ( loss = 'hinge',\n",
    "              # Adam is a kind of gradient descent\n",
    "              optimizer = optimizers.Adam ( lr = learning_rate ),\n",
    "              #metrics = [ 'accuracy' ] \n",
    "                )\n",
    "\n",
    "# train the parameters\n",
    "history = model.fit ( train_X, train_y, epochs = 2, batch_size = batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10621620/10621620 [==============================] - 133s 12us/step\n",
      "Training accuracy: 0.0012987661027600089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate ( train_X, train_y, batch_size = 32 )\n",
    "# test_acc = model.evaluate ( test_X, test_y, batch_size = 32 )[1]\n",
    "print ( 'Training accuracy: %s' % train_acc )\n",
    "#print ( 'Testing accuracy: %s' % test_acc )\n",
    "\n",
    "losses = history.history['loss']\n",
    "#plt.plot ( range ( len ( losses ) ), losses, 'r' )\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "def M_findDeviceByCookie(browser, cookie):\n",
    "    clf = SVC(gamma='auto')\n",
    "    score = clf.fit(browser, cookie)\n",
    "    return score, clf\n",
    "score, M_clf = M_findDeviceByCookie(trainEnc_df.browser, trainEnc_df.cookie_pta)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIXNET_Recommendation:\n",
    "    \n",
    "    def __init__(self,training_data_folder=\"data/training\",test_data_file_path=\"data/testing.json\",target_file_path=\"tmp/recommendation\",k=20):\n",
    "        self.training_data_folder = training_data_folder\n",
    "        self.test_data_file_path = test_data_file_path\n",
    "        self.target_file_path = target_file_path\n",
    "        self.k = k\n",
    "    \n",
    "    def load_data(self):\n",
    "        data_set ={}\n",
    "        training_files = os.listdir(self.training_data_folder)\n",
    "        print(training_files)\n",
    "        for filename in training_files:\n",
    "            for line in open(\"%s/%s\"%(self.training_data_folder,filename)):\n",
    "                data_json = json.loads(line.strip())\n",
    "                if data_json['cookie_pta'] not in data_set:\n",
    "                    data_set[data_json['cookie_pta']]={}\n",
    "                data_set[data_json['cookie_pta']][data_json['author_id']] = 1\n",
    "        v = DictVectorizer(sparse=True)\n",
    "        X = v.fit_transform(data_set.values()).T\n",
    "        author = v.get_feature_names()\n",
    "        self.data_set =data_set\n",
    "        self.X = X\n",
    "        self.author = author\n",
    "    \n",
    "    def calculate_item_similarity(self):\n",
    "        X = self.X\n",
    "        author = self.author\n",
    "        distance = sum(X.T.toarray())\n",
    "        similarity_tmp_file = open(\"tmp/similarity_top10\",\"w\")\n",
    "        count = 0\n",
    "        size_per_loop =1000\n",
    "        while count< X.shape[0]:\n",
    "            size_max = min(count+size_per_loop,X.shape[0])-count\n",
    "            similarity = X[count:min(count+size_per_loop,X.shape[0])].dot(X.T).toarray()\n",
    "            for i in xrange(size_max):\n",
    "                similarity[i] = similarity[i]/numpy.sqrt(distance[count+i])\n",
    "            similarity = similarity.T\n",
    "            for i in xrange(X.shape[0]):\n",
    "                similarity[i] = numpy.round(similarity[i]/numpy.sqrt(distance[i]),2)\n",
    "            similarity = similarity.T\n",
    "            for i in xrange(size_max):\n",
    "                rank = []\n",
    "                for j in xrange(X.shape[0]):\n",
    "                    if similarity[i][j] >0.99:\n",
    "                        similarity[i][j] = 0\n",
    "                    rank.append(similarity[i][j])\n",
    "                top_k_similarity = heapq.nlargest(self.k, xrange(len(rank)), rank.__getitem__)\n",
    "                data =[]\n",
    "                for j in xrange(len(top_k_similarity)):\n",
    "                    data.append(\"%s,%.2f\"%(author[top_k_similarity[j]],rank[top_k_similarity[j]]))\n",
    "                similarity_tmp_file.write(\";\".join(data)+\"\\n\")\n",
    "            del similarity\n",
    "            count+=size_per_loop\n",
    "        similarity_tmp_file.close()\n",
    "    \n",
    "    def load_recommend_target(self):\n",
    "        target_file = open(self.test_data_file_path)\n",
    "        questions = {}\n",
    "        for i in target_file:\n",
    "            j =json.loads(i)\n",
    "            questions[j['cookie_pta']] = 1\n",
    "        target_file.close()\n",
    "        self.questions= questions\n",
    "    \n",
    "    def recommend_from_item_similarity(self):\n",
    "        data_set =self.data_set\n",
    "        questions = self.questions\n",
    "        author = self.author\n",
    "        f = open(\"tmp/similarity_top10\")\n",
    "        count =0\n",
    "        author_recommend = {}\n",
    "        for i in f:\n",
    "            r =i.strip().split(\";\")\n",
    "            author_recommend[author[count]] = {}\n",
    "            for j in r:\n",
    "                a = j.split(\",\")\n",
    "                author_recommend[author[count]][a[0]] = float(a[1])\n",
    "            count +=1\n",
    "        f_out = open(self.target_file_path,\"w\")\n",
    "        for i in questions.keys():\n",
    "            log = data_set[i]\n",
    "            recommend_author = {}\n",
    "            for author_id in log.keys():\n",
    "                for r_author in author_recommend[author_id]:\n",
    "                    if r_author in log:\n",
    "                        continue\n",
    "                    if r_author not in recommend_author:\n",
    "                        recommend_author[r_author] = 0\n",
    "                    recommend_author[r_author] += author_recommend[author_id][r_author]\n",
    "            js = {\"cookie_pta\":i,\"author_id\":heapq.nlargest(len(recommend_author)/20,recommend_author,key=recommend_author.__getitem__)}\n",
    "            f_out.write(json.dumps(js)+\"\\n\")\n",
    "        f_out.close()\n",
    "\n",
    "    def main(self):\n",
    "        self.load_data()\n",
    "        self.calculate_item_similarity()\n",
    "        self.load_recommend_target()\n",
    "        self.recommend_from_item_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['part-00022', 'part-00016', 'part-00012', 'part-00020', 'part-00001', 'part-00005', 'part-00006', 'part-00023', 'part-00008', 'part-00015', 'part-00007', 'part-00002', 'part-00003', 'part-00013', 'part-00000', 'part-00017', 'part-00010', 'part-00014', 'part-00004', 'part-00018', 'part-00011', 'part-00021', 'part-00009', 'part-00019']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a02fe56c5854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrecommendation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIXNET_Recommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecommendation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-57ee24fee08e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m#elf.calculate_item_similarity()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m#self.load_recommend_target()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-57ee24fee08e>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_data_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mdata_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cookie_pta'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cookie_pta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recommendation = PIXNET_Recommendation()\n",
    "recommendation.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
